Evaluate how well pretrained GPT-2 (124M parameters) can perform integer multiplication without any fine-tuning.

RESEARCH QUESTION:
Can a pretrained language model perform arithmetic multiplication accurately, and how does performance vary with problem difficulty?

TASK:
1. Evaluate pretrained GPT-2 on multiplication problems of varying difficulty (single-digit through multi-digit)
2. Analyze accuracy patterns, error types, and failure modes
3. Generate visualizations showing performance vs difficulty
4. Write a research paper with your findings

EVALUATION METHODOLOGY:
- Generate test sets programmatically (50-100 problems per difficulty level)
- Use appropriate prompting strategies
- Measure exact match accuracy and analyze near-miss patterns
- Calculate mean absolute error for incorrect answers
- Track inference time

TECHNICAL CONSTRAINTS:
- **CRITICAL**: The local machine does NOT have a GPU
- **MANDATORY**: Use Modal for ALL GPU operations (model loading, inference, evaluation)
  * Import modal and create app: app = modal.App("gpt2-multiplication")
  * Decorate compute functions with: @app.function(gpu="T4", timeout=1800)
  * Modal is already installed and authenticated
  * ALL model inference MUST run on Modal or it will fail
- GPT-2 (124M) is available via transformers library
- Keep total compute time to 10-30 minutes on GPU (budget <$1)
- Generate all test data programmatically

PAPER REQUIREMENTS:
- Standard sections: Introduction, Methods, Results, Discussion, Conclusion
- Include tables showing accuracy by difficulty level
- Include figures: accuracy vs difficulty plots, error distributions
- Discuss patterns in model failures
- Write in complete paragraphs (no bullet lists in main text)
- Anonymous authorship

IMPORTANT:
- NO training or fine-tuning (evaluation only)
- ALL model inference must happen on Modal (local machine has no GPU)
